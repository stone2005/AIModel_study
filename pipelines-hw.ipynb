{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e592eee-fccb-431c-a70b-6d57af63bb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge ipywidgets -y\n",
    "!conda update jupyter -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c38e82-e8f6-4af0-b257-b46f446aa249",
   "metadata": {
    "tags": []
   },
   "source": [
    "## transformers 自定义模型下载的路径\n",
    "\n",
    "在transformers自定义模型下载的路径方法\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.environ['HF_HOME'] = '/mnt/new_volume/hf'\n",
    "os.environ['HF_HUB_CACHE'] = '/mnt/new_volume/hf/hub'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9684ec5f-9460-4876-9883-69380eacb0e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/root/miniconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of Qwen2ForSequenceClassification were not initialized from the model checkpoint at Qwen/Qwen1.5-1.8B and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import os\n",
    "# 加镜像提一下速\n",
    "os.environ['HF_ENDPOINT'] = \"https://hf-mirror.com\"\n",
    "# 使用预训练的情感分析模型\n",
    "#model_name = 'uer/roberta-base-finetuned-jd-binary-chinese'\n",
    "#model_name = 'lxyuan/distilbert-base-multilingual-cased-sentiments-student'\n",
    "#model_name = 'Qwen/Qwen1.5-0.5B'\n",
    "model_name = 'Qwen/Qwen1.5-1.8B'\n",
    "# 和默认的模型做一下对比\n",
    "pipe = pipeline(task=\"sentiment-analysis\")\n",
    "pipe_qw = pipeline(task=\"sentiment-analysis\",\n",
    "                model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1390396e-1af8-497f-85d9-6c9e984b4609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "默认模型的结果=======\n",
      "Text: 今儿上海可真冷啊 -> Sentiment: {'label': 'NEGATIVE', 'score': 0.8957212567329407}\n",
      "Text: Today Shanghai is really cold. -> Sentiment: {'label': 'NEGATIVE', 'score': 0.9995032548904419}\n",
      "Text: 你学东西真的好快，理论课一讲就明白了 -> Sentiment: {'label': 'NEGATIVE', 'score': 0.8578682541847229}\n",
      "Text: You learn things really quickly. You understand the theory class as soon as it is taught. -> Sentiment: {'label': 'POSITIVE', 'score': 0.9961802959442139}\n",
      "Text: 他这个人老是爱发牢骚，传播不好的消息 -> Sentiment: {'label': 'NEGATIVE', 'score': 0.9664023518562317}\n",
      "Text: 我觉得这个白切鸡的味道比较一般般. -> Sentiment: {'label': 'NEGATIVE', 'score': 0.9438255429267883}\n",
      "Text: 麻婆豆腐的味道绝了. -> Sentiment: {'label': 'NEGATIVE', 'score': 0.9343594312667847}\n",
      "Text: 这道菜让我完全停不下来啊。 -> Sentiment: {'label': 'NEGATIVE', 'score': 0.9677881002426147}\n",
      "千问的结果======\n",
      "Text: 今儿上海可真冷啊 -> Sentiment: {'label': 'LABEL_1', 'score': 0.995270311832428}\n",
      "Text: Today Shanghai is really cold. -> Sentiment: {'label': 'LABEL_0', 'score': 0.9999628067016602}\n",
      "Text: 你学东西真的好快，理论课一讲就明白了 -> Sentiment: {'label': 'LABEL_1', 'score': 0.9952011108398438}\n",
      "Text: You learn things really quickly. You understand the theory class as soon as it is taught. -> Sentiment: {'label': 'LABEL_0', 'score': 0.8149805665016174}\n",
      "Text: 他这个人老是爱发牢骚，传播不好的消息 -> Sentiment: {'label': 'LABEL_1', 'score': 0.9998981952667236}\n",
      "Text: 我觉得这个白切鸡的味道比较一般般. -> Sentiment: {'label': 'LABEL_1', 'score': 0.9988528490066528}\n",
      "Text: 麻婆豆腐的味道绝了. -> Sentiment: {'label': 'LABEL_1', 'score': 0.9853663444519043}\n",
      "Text: 这道菜让我完全停不下来啊。 -> Sentiment: {'label': 'LABEL_1', 'score': 0.9942628741264343}\n"
     ]
    }
   ],
   "source": [
    "text_list = [\n",
    "    \"今儿上海可真冷啊\",\n",
    "    \"Today Shanghai is really cold.\",\n",
    "    \"你学东西真的好快，理论课一讲就明白了\",\n",
    "    \"You learn things really quickly. You understand the theory class as soon as it is taught.\",\n",
    "    \"他这个人老是爱发牢骚，传播不好的消息\",\n",
    "    \"我觉得这个白切鸡的味道比较一般般.\",\n",
    "    \"麻婆豆腐的味道绝了.\",\n",
    "    \"这道菜让我完全停不下来啊。\"\n",
    "]\n",
    "print(\"默认模型的结果=======\")\n",
    "results_default = pipe(text_list)\n",
    "for text, result in zip(text_list, results_default):\n",
    "    print(f\"Text: {text} -> Sentiment: {result}\")\n",
    "print(\"千问的结果======\")\n",
    "results_qwen = pipe_qw(text_list)\n",
    "for text, result in zip(text_list, results_qwen):\n",
    "    print(f\"Text: {text} -> Sentiment: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1ed125-f9ed-42d9-b102-dbc3172baefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at dbmdz/bert-large-cased-finetuned-conll03-english were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_name = 'shibing624/bert4ner-base-chinese'\n",
    "\n",
    "classifier = pipeline(task=\"ner\")\n",
    "classifier_2 = pipeline(task=\"ner\",\n",
    "                     model = model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68bab77c-0fe6-4781-b978-02d56829db33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classfier 1 result:\n",
      "\n",
      "{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}\n",
      "{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}\n",
      "{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}\n",
      "{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}\n",
      "{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}\n",
      "classfier 2 result:\n",
      "\n",
      "{'entity': 'B-LOC', 'score': 0.9984, 'index': 6, 'word': '美', 'start': 15, 'end': 16}\n",
      "{'entity': 'I-LOC', 'score': 0.9987, 'index': 7, 'word': '国', 'start': 16, 'end': 17}\n",
      "{'entity': 'B-LOC', 'score': 0.9975, 'index': 8, 'word': '纽', 'start': 17, 'end': 18}\n",
      "{'entity': 'I-LOC', 'score': 0.999, 'index': 9, 'word': '约', 'start': 18, 'end': 19}\n",
      "{'entity': 'B-LOC', 'score': 0.9981, 'index': 11, 'word': '法', 'start': 20, 'end': 21}\n",
      "{'entity': 'I-LOC', 'score': 0.9982, 'index': 12, 'word': '国', 'start': 21, 'end': 22}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\"Hugging Face is a French company based in New York City.\")\n",
    "\n",
    "preds = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds\n",
    "]\n",
    "print(\"classfier 1 result:\\n\")\n",
    "print(*preds, sep=\"\\n\")\n",
    "\n",
    "preds_2 = classifier_2(\"HugingFace 是一家在美国纽约的法国公司.\")\n",
    "preds_2 = [\n",
    "    {\n",
    "        \"entity\": pred[\"entity\"],\n",
    "        \"score\": round(pred[\"score\"], 4),\n",
    "        \"index\": pred[\"index\"],\n",
    "        \"word\": pred[\"word\"],\n",
    "        \"start\": pred[\"start\"],\n",
    "        \"end\": pred[\"end\"],\n",
    "    }\n",
    "    for pred in preds_2\n",
    "]\n",
    "print(\"classfier 2 result:\\n\")\n",
    "print(*preds_2, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c72d55-e574-444f-96bc-62704022a148",
   "metadata": {},
   "source": [
    "#### 合并实体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b441191-6156-44b8-a323-db461ad06efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.11/site-packages/transformers/pipelines/token_classification.py:169: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'LOC',\n",
       "  'score': 0.9986733,\n",
       "  'word': '美 国',\n",
       "  'start': 15,\n",
       "  'end': 17},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.9983698,\n",
       "  'word': '纽 约',\n",
       "  'start': 17,\n",
       "  'end': 19},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99834716,\n",
       "  'word': '法 国',\n",
       "  'start': 20,\n",
       "  'end': 22}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_2 = pipeline(task=\"ner\", model=model_name, grouped_entities=True)\n",
    "classifier_2(\"HugingFace 是一家在美国纽约的法国公司。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5281b0b-6b57-4884-92e1-cc2677987360",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model 'LayoutLMForQuestionAnswering' is not supported for question-answering. Supported models are ['AlbertForQuestionAnswering', 'BartForQuestionAnswering', 'BertForQuestionAnswering', 'BigBirdForQuestionAnswering', 'BigBirdPegasusForQuestionAnswering', 'BloomForQuestionAnswering', 'CamembertForQuestionAnswering', 'CanineForQuestionAnswering', 'ConvBertForQuestionAnswering', 'Data2VecTextForQuestionAnswering', 'DebertaForQuestionAnswering', 'DebertaV2ForQuestionAnswering', 'DistilBertForQuestionAnswering', 'ElectraForQuestionAnswering', 'ErnieForQuestionAnswering', 'ErnieMForQuestionAnswering', 'FalconForQuestionAnswering', 'FlaubertForQuestionAnsweringSimple', 'FNetForQuestionAnswering', 'FunnelForQuestionAnswering', 'GPT2ForQuestionAnswering', 'GPTNeoForQuestionAnswering', 'GPTNeoXForQuestionAnswering', 'GPTJForQuestionAnswering', 'IBertForQuestionAnswering', 'LayoutLMv2ForQuestionAnswering', 'LayoutLMv3ForQuestionAnswering', 'LEDForQuestionAnswering', 'LiltForQuestionAnswering', 'LongformerForQuestionAnswering', 'LukeForQuestionAnswering', 'LxmertForQuestionAnswering', 'MarkupLMForQuestionAnswering', 'MBartForQuestionAnswering', 'MegaForQuestionAnswering', 'MegatronBertForQuestionAnswering', 'MobileBertForQuestionAnswering', 'MPNetForQuestionAnswering', 'MptForQuestionAnswering', 'MraForQuestionAnswering', 'MT5ForQuestionAnswering', 'MvpForQuestionAnswering', 'NezhaForQuestionAnswering', 'NystromformerForQuestionAnswering', 'OPTForQuestionAnswering', 'QDQBertForQuestionAnswering', 'ReformerForQuestionAnswering', 'RemBertForQuestionAnswering', 'RobertaForQuestionAnswering', 'RobertaPreLayerNormForQuestionAnswering', 'RoCBertForQuestionAnswering', 'RoFormerForQuestionAnswering', 'SplinterForQuestionAnswering', 'SqueezeBertForQuestionAnswering', 'T5ForQuestionAnswering', 'UMT5ForQuestionAnswering', 'XLMForQuestionAnsweringSimple', 'XLMRobertaForQuestionAnswering', 'XLMRobertaXLForQuestionAnswering', 'XLNetForQuestionAnsweringSimple', 'XmodForQuestionAnswering', 'YosoForQuestionAnswering'].\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_name = 'impira/layoutlm-document-qa'\n",
    "question_answerer = pipeline(task=\"question-answering\",model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca674a51-30a4-4dea-a443-e428925e990f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.0, start: 30, end: 41, answer: huggingface\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the name of the repository?\",\n",
    "    context=\"The name of the repository is huggingface/transformers\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2158feb-a528-410a-aabf-f3bd7f2726c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 0.0, start: 97, end: 113, answer: Tiananmen Square\n"
     ]
    }
   ],
   "source": [
    "preds = question_answerer(\n",
    "    question=\"What is the capital of China?\",\n",
    "    context=\"On 1 October 1949, CCP Chairman Mao Zedong formally proclaimed the People's Republic of China in Tiananmen Square, Beijing.\",\n",
    ")\n",
    "print(\n",
    "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e028f36-2b50-4ae3-8dce-2f0ac685e8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "#model_name = \"t5-base\"\n",
    "model_name = \"Falconsai/text_summarization\"\n",
    "summarizer = pipeline(task=\"summarization\",\n",
    "                      model=model_name,\n",
    "                      min_length=8,\n",
    "                      max_length=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c760bbf-2ae4-4f84-bd5e-32c30ee6bd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Transformer is the first sequence transduction model based entirely on attention . For translation tasks, the Transformer can be trained significantly faster than architectures based'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    \"\"\"\n",
    "    In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, \n",
    "    replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. \n",
    "    For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. \n",
    "    On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. \n",
    "    In the former task our best model outperforms even all previously reported ensembles.\n",
    "    \"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b50ff52b-e61e-40cd-ab66-a591dc0c3b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data . The underlying transformer is'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer(\n",
    "    '''\n",
    "    Large language models (LLM) are very large deep learning models that are pre-trained on vast amounts of data. \n",
    "    The underlying transformer is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities. \n",
    "    The encoder and decoder extract meanings from a sequence of text and understand the relationships between words and phrases in it.\n",
    "    Transformer LLMs are capable of unsupervised training, although a more precise explanation is that transformers perform self-learning. \n",
    "    It is through this process that transformers learn to understand basic grammar, languages, and knowledge.\n",
    "    Unlike earlier recurrent neural networks (RNN) that sequentially process inputs, transformers process entire sequences in parallel. \n",
    "    This allows the data scientists to use GPUs for training transformer-based LLMs, significantly reducing the training time.\n",
    "    '''\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d4c1e9-8a67-4c72-8dce-ab326e0bc3b6",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装\n",
    "\n",
    "建议在命令行安装必要的音频数据处理包: ffmpeg\n",
    "\n",
    "```shell\n",
    "$apt update & apt upgrade\n",
    "$apt install -y ffmpeg\n",
    "$pip install ffmpeg ffmpeg-python\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e1f8a8d-75eb-49ab-9353-6c9d1f384cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.11/site-packages/transformers/audio_utils.py:198: UserWarning: At least one mel filter has all zero values. The value for `num_mel_filters` (128) may be set too high. Or, the value for `num_frequency_bins` (256) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#model_name = \"superb/hubert-base-superb-er\"\n",
    "model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "classifier = pipeline(task=\"audio-classification\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "204a4159-d14d-4623-8340-93d15abcc549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4209, 'label': 'Speech'},\n",
       " {'score': 0.1792, 'label': 'Rain on surface'},\n",
       " {'score': 0.13, 'label': 'Rain'},\n",
       " {'score': 0.0959, 'label': 'Raindrop'},\n",
       " {'score': 0.0578, 'label': 'Music'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用 Hugging Face Datasets 上的测试文件\n",
    "preds = classifier(\"https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2528bf81-8289-4bb9-bf2d-c0ce9f7e8b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.4209, 'label': 'Speech'},\n",
       " {'score': 0.1792, 'label': 'Rain on surface'},\n",
       " {'score': 0.13, 'label': 'Rain'},\n",
       " {'score': 0.0959, 'label': 'Raindrop'},\n",
       " {'score': 0.0578, 'label': 'Music'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用本地的音频文件做测试\n",
    "preds = classifier(\"data/audio/mlk.flac\")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d14f8c-1571-4889-abd4-8fde09dc610a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-base-960h were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_g', 'wav2vec2.encoder.pos_conv_embed.conv.weight_v']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1', 'wav2vec2.masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# 使用 `model` 参数指定模型\n",
    "model_name = 'facebook/wav2vec2-base-960h'\n",
    "transcriber = pipeline(task=\"automatic-speech-recognition\", model='openai/whisper-small')\n",
    "transcriber_2 = pipeline(task=\"automatic-speech-recognition\", model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "316ebe18-9c8e-4ded-96b7-751304aa9122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai whisper small: \n",
      "{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}\n",
      "wav2vect-base: \n",
      "{'text': 'I HAVE A DREAM BUT ONE DAY THIS NATION WILL RISE UP LIVE UP THE TRUE MEANING OF ITS TREES'}\n"
     ]
    }
   ],
   "source": [
    "text = transcriber(\"data/audio/mlk.flac\")\n",
    "text_2 = transcriber_2(\"data/audio/mlk.flac\")\n",
    "print(\"openai whisper small: \")\n",
    "print(text)\n",
    "print(\"wav2vect-base: \")\n",
    "print(text_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ca9736-10b9-45b0-a3e3-925f153bab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/peft/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_name = 'microsoft/resnet-50'\n",
    "#classifier = pipeline(task=\"image-classification\")\n",
    "classifier = pipeline(task=\"image-classification\",model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8a41647-e8db-4d29-9dac-06c3c145acaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5874, 'label': 'lynx, catamount'}\n",
      "{'score': 0.1289, 'label': 'tabby, tabby cat'}\n",
      "{'score': 0.075, 'label': 'marmot'}\n",
      "{'score': 0.0382, 'label': 'badger'}\n",
      "{'score': 0.0131, 'label': 'Egyptian cat'}\n"
     ]
    }
   ],
   "source": [
    "preds = classifier(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ecb60-ebb9-4f4e-82bc-21e79bb22d90",
   "metadata": {},
   "source": [
    "![](data/image/cat-chonk.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "67592129-6430-4349-8016-7dde511ff69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.5874, 'label': 'lynx, catamount'}\n",
      "{'score': 0.1289, 'label': 'tabby, tabby cat'}\n",
      "{'score': 0.075, 'label': 'marmot'}\n",
      "{'score': 0.0382, 'label': 'badger'}\n",
      "{'score': 0.0131, 'label': 'Egyptian cat'}\n"
     ]
    }
   ],
   "source": [
    "# 使用本地图片（狼猫）\n",
    "preds = classifier(\n",
    "    \"data/image/cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113c251-a648-4ea2-baa4-3081bb490c70",
   "metadata": {},
   "source": [
    "![](data/image/panda.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e9b51a-d759-4398-9894-f10933dbed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9768, 'label': 'giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca'}\n",
      "{'score': 0.0088, 'label': 'indri, indris, Indri indri, Indri brevicaudatus'}\n",
      "{'score': 0.0004, 'label': 'groenendael'}\n",
      "{'score': 0.0003, 'label': 'Siberian husky'}\n",
      "{'score': 0.0002, 'label': 'malamute, malemute, Alaskan malamute'}\n"
     ]
    }
   ],
   "source": [
    "# 使用本地图片（熊猫）\n",
    "preds = classifier(\n",
    "    \"data/image/panda.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"]} for pred in preds]\n",
    "print(*preds, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7122f04-7add-4623-8f3f-ccc00247524b",
   "metadata": {},
   "source": [
    "#### 前置依赖包安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cbc4227-cbcc-4f18-bf26-66535e66afb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /root/miniconda3/envs/peft/lib/python3.11/site-packages (0.9.12)\n",
      "Requirement already satisfied: torch>=1.7 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from timm) (2.3.0)\n",
      "Requirement already satisfied: torchvision in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from timm) (0.18.0)\n",
      "Requirement already satisfied: pyyaml in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from timm) (0.23.2)\n",
      "Requirement already satisfied: safetensors in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from timm) (0.4.3)\n",
      "Requirement already satisfied: filelock in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (4.12.0)\n",
      "Requirement already satisfied: sympy in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (3.3)\n",
      "Requirement already satisfied: jinja2 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torch>=1.7->timm) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.7->timm) (12.5.40)\n",
      "Requirement already satisfied: packaging>=20.9 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from huggingface-hub->timm) (24.0)\n",
      "Requirement already satisfied: requests in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from huggingface-hub->timm) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from huggingface-hub->timm) (4.66.4)\n",
      "Requirement already satisfied: numpy in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from torchvision->timm) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from jinja2->torch>=1.7->timm) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from requests->huggingface-hub->timm) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /root/miniconda3/envs/peft/lib/python3.11/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3401126-756b-4394-930c-c833c1f574b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/detr-resnet-50 and revision 2729413 (https://huggingface.co/facebook/detr-resnet-50).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Some weights of the model checkpoint at facebook/detr-resnet-50 were not used when initializing DetrForObjectDetection: ['model.backbone.conv_encoder.model.layer1.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked', 'model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked']\n",
      "- This IS expected if you are initializing DetrForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DetrForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "model_name = 'hustvl/yolos-tiny'\n",
    "detector = pipeline(task=\"object-detection\")\n",
    "detector_2 = pipeline(task=\"object-detection\",model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32dc65d4-3868-4d10-a433-9f50832e8e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9864, 'label': 'cat', 'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "print(preds)\n",
    "preds_2 = detector_2(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg\"\n",
    ")\n",
    "preds_2 = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds_2]\n",
    "print(preds_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550759be-93ab-4988-81f0-c0cb8eccfda8",
   "metadata": {},
   "source": [
    "![](data/image/cat_dog.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40f66cd7-f2c8-4af3-b9ab-60012792ec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.9985, 'label': 'cat', 'box': {'xmin': 78, 'ymin': 57, 'xmax': 309, 'ymax': 371}}, {'score': 0.989, 'label': 'dog', 'box': {'xmin': 279, 'ymin': 20, 'xmax': 482, 'ymax': 416}}]\n",
      "[{'score': 0.9946, 'label': 'cat', 'box': {'xmin': 75, 'ymin': 60, 'xmax': 290, 'ymax': 369}}, {'score': 0.9899, 'label': 'dog', 'box': {'xmin': 280, 'ymin': 18, 'xmax': 479, 'ymax': 416}}]\n"
     ]
    }
   ],
   "source": [
    "preds = detector(\n",
    "    \"data/image/cat_dog.jpg\"\n",
    ")\n",
    "preds = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds]\n",
    "print(preds)\n",
    "\n",
    "preds_2 = detector_2(\n",
    "    \"data/image/cat_dog.jpg\"\n",
    ")\n",
    "preds_2 = [{\"score\": round(pred[\"score\"], 4), \"label\": pred[\"label\"], \"box\": pred[\"box\"]} for pred in preds_2]\n",
    "print(preds_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4993a9f-1032-46ab-97b1-a028d4bd5ebc",
   "metadata": {},
   "source": [
    "### Homework：替换以上示例中的模型，对比不同模型在相同任务上的性能表现\n",
    "\n",
    "在 Hugging Face Models 中找到适合你的模型：https://huggingface.co/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f51d2-863d-44f6-836f-9051351985ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
